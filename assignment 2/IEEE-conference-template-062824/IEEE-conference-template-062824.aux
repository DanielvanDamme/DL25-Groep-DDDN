\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{belhadi2025eeg}
\citation{lecun2015deep}
\citation{besserve2007classification}
\citation{lawhern2018eegnet}
\citation{zhang2018cascade}
\citation{abdellaoui2020deepbrainstateclassification}
\citation{lawhern2018eegnet}
\citation{zhang2018cascade}
\citation{abdellaoui2020deepbrainstateclassification}
\citation{vaswani2017attention}
\citation{ali2024comprehensive}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Methods}{1}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Model Selection}{1}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}1}Spatial Considerations}{1}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}2}Temporal Considerations}{1}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}3}Attention Mechanisms}{1}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}4}Normalization}{2}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}5}Downsampling}{2}{subsubsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Model Descriptions}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Hyperparameter Tuning}{2}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Intra results}{2}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Loss over epochs for the intra-subject classification models.}}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intra_loss_over_epoch}{{1}{3}{Loss over epochs for the intra-subject classification models}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Cross results}{3}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Loss and Accuracy per Model and Task}}{3}{table.caption.5}\protected@file@percent }
\newlabel{tab:cross_model_results}{{I}{3}{Loss and Accuracy per Model and Task}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Accuracy differences Intra vs Cross}{3}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Loss over epochs for the cross-subject classification models.}}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:cross_loss_over_epoch}{{2}{4}{Loss over epochs for the cross-subject classification models}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Accuracy over epochs for the cross-subject classification models.}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:cross_accuracy_over_epoch}{{3}{4}{Accuracy over epochs for the cross-subject classification models}{figure.caption.3}{}}
\citation{gramfort2013meg}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test loss for the cross-subject classification models. The x-axis shows the model, and the y-axis shows the loss. The bars are grouped by test set.}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:test_loss_bars}{{4}{5}{Test loss for the cross-subject classification models. The x-axis shows the model, and the y-axis shows the loss. The bars are grouped by test set}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Discussion}{5}{section.6}\protected@file@percent }
\newlabel{discussion}{{VI}{5}{Discussion}{section.6}{}}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{belhadi2025eeg}{1}
\bibcite{lecun2015deep}{2}
\bibcite{besserve2007classification}{3}
\bibcite{lawhern2018eegnet}{4}
\bibcite{zhang2018cascade}{5}
\bibcite{abdellaoui2020deepbrainstateclassification}{6}
\bibcite{vaswani2017attention}{7}
\bibcite{ali2024comprehensive}{8}
\bibcite{gramfort2013meg}{9}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Limitations}{6}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{6}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Here the t-SNE embedding dimensions of the training set and test sets. This is the dimension reduction done on the distribution of the principal components of the original data. It shows the clustering of those points in the t-SNE space. Here we can see that test set 1 resembles the training set the most, after this test set 3, and finally test set 2 which is clearly shifted. This is in accordance with \textsc  {pca-feedforward-model}}}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:tsne_distribution_shift}{{5}{7}{Here the t-SNE embedding dimensions of the training set and test sets. This is the dimension reduction done on the distribution of the principal components of the original data. It shows the clustering of those points in the t-SNE space. Here we can see that test set 1 resembles the training set the most, after this test set 3, and finally test set 2 which is clearly shifted. This is in accordance with \textsc {pca-feedforward-model}}{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Centroid distance between train and test sets in t-SNE space. Showcasing the distribution shift of test set 2 compared to the training set. Test set 2 is clearly the most shifted because its centroid is further away from the train centroid. On average every test set 2 sample is more distant from the train samples.}}{7}{table.caption.10}\protected@file@percent }
\newlabel{tab:centroid_distance}{{II}{7}{Centroid distance between train and test sets in t-SNE space. Showcasing the distribution shift of test set 2 compared to the training set. Test set 2 is clearly the most shifted because its centroid is further away from the train centroid. On average every test set 2 sample is more distant from the train samples}{table.caption.10}{}}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{7}
