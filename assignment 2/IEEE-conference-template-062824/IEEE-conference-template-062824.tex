\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{hyperref}
\usepackage{url}
\usepackage{subcaption}
\usepackage{float}
\usepackage{placeins}
\usepackage{svg}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em\textsc{i}\kern-.025em b\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{TODO}

\author{\IEEEauthorblockN{Dani\"el Jochems}
\IEEEauthorblockN{David Huizinga}
\IEEEauthorblockN{Niek Grimbergen}
\IEEEauthorblockN{Daan van Dam}}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\section{Methods}

\subsection{Data Engineering}

\subsubsection{Normalization}
To normalize the data, we applied min-max scaling, bringing each feature to the [0,1] range based on the global minimum and maximum values computed from the entire training set. This approach preserves the relative structure of the data while ensuring all features operate on a comparable scale, especially with sensor-based time-series inputs. The normalization is implemented in the scale_data function and applied uniformly to both training and test sets, using the training statistics only. We do this to ensure consistency across the entire pipeline.

\subsubsection{Downsampling}
We applied uniform downsampling to the data to reduce temporal resolution and computational load. This is done by selecting a fixed proportion of timesteps in evenly spaced intervals accross the full sequence, in our case we chose this to be 10 percent \texttt{[motivatie voor 10 procent]}. With this implementation we compute the stride based on the downsampeling factor and select indices accordingly, ensuring consistent coverage of the original signal. 

\subsection{Model Description}


\subsection{Hyperparameter Tuning}

\section{Results}

\section{Discussion}
An attempt was made to do some specific MEG preprocessing like namely, a fixed bandpass filter, prepare
channel z-scoring, and baseline correction. The inspiration for these came from the 
\href{https://mne.tools/stable/index.html}{MNE tools} package and the corresponding paper by Gramfort et al 
\cite{gramfort2013meg}. This applied preprocessing before model training severaly impacted results.
Together they destroyed the signal for effective classification, rendering the model useless at 
classifying. per channel z-scoring alone was effective.

\section*{AI Statement}

\bibliographystyle{IEEEtran}
\bibliography{references}

\section*{Supplementary Materials}
[Placeholder for supplementary figures or results]

\clearpage
\onecolumn

\end{document}