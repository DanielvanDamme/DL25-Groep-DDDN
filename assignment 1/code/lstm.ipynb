{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fd6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "matlab = scipy.io.loadmat('Xtrain.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dba20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = matlab['Xtrain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9037af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d881557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a list\n",
    "X_train_list = X_train.flatten().tolist()\n",
    "print(X_train_list)\n",
    "\n",
    "# Plot a line of the values in the training set\n",
    "fig = px.line(y=X_train_list, x=range(len(X_train_list)), title='Line Plot of X_train Values')\n",
    "fig.update_layout(xaxis_title='Index', yaxis_title='Value') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c473b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(timeseries_array, n_lags):\n",
    "    df = pd.DataFrame(timeseries_array, columns=['label'])\n",
    "    for i in range(1, n_lags + 1):\n",
    "        df[f'lag {i}'] = df['label'].shift(i)\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns=['label']).to_numpy()\n",
    "    y = df['label'].to_numpy()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_features(X_train_list, 10)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c94c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_cv_sets(X, y, folds: int, validation_split_ratio: float = 0.2):\n",
    "    \n",
    "    n = len(X)\n",
    "    fold_size = int(n / folds)\n",
    "\n",
    "    for fold in range(folds):\n",
    "        start_fold = fold * fold_size\n",
    "        end_fold = start_fold + fold_size\n",
    "\n",
    "        training_start = 0\n",
    "        training_end = int(end_fold - fold_size * validation_split_ratio)\n",
    "\n",
    "        validation_start = training_end\n",
    "\n",
    "        training_set = X[training_start:training_end], y[training_start:training_end]\n",
    "        validation_set = X[validation_start:end_fold], y[validation_start:end_fold]\n",
    "        yield training_set, validation_set\n",
    "\n",
    "# Example usage\n",
    "folds = 5\n",
    "for train_set, val_set in expanding_window_cv_sets(X, y, folds):\n",
    "    train_X, train_y = train_set\n",
    "    val_X, val_y = val_set\n",
    "\n",
    "    print(\"Training Set:\")\n",
    "    print(train_X.shape, train_y.shape)\n",
    "    print(\"Validation Set:\")\n",
    "    print(val_X.shape, val_y.shape)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ea6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two tables to store the results of CV grid search\n",
    "epoch_grid_search_results = pd.DataFrame(columns=['epoch', 'fold', 'MSE', 'MAE'])\n",
    "grid_search_results = pd.DataFrame(columns=['hidden_units', 'lags', 'fold', 'MSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b94c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "EPOCHS = [10, 20, 50, 100, 500, 1000]\n",
    "LAGS = [5, 15, 25, 35, 50]\n",
    "HIDDEN_UNITS = [5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = create_features(X_train_list, 25)\n",
    "\n",
    "for epoch in EPOCHS:\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for fold, (train_set, val_set) in enumerate(expanding_window_cv_sets(X, y, folds)):\n",
    "\n",
    "        train_X, train_y = train_set\n",
    "        val_X, val_y = val_set\n",
    "        \n",
    "        # Reshape the data to be 3D for LSTM input\n",
    "        train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "        val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "        # First, we are gonna fix the LSTM to 10 hidden units and grid search the epochs\n",
    "\n",
    "        # Define the lSTM model with 15 hidden units\n",
    "        model = Sequential([\n",
    "            LSTM(10, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(train_X, train_y, epochs=epoch, batch_size=32, verbose=0)\n",
    "\n",
    "        # Recursively predict the validation set, so start with the first example of the validation set and use the model to predict the next value, then use that value to predict the next one, and so on.\n",
    "        current_input = val_X[0].reshape((1, 1, val_X.shape[2]))\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(len(val_y)):\n",
    "            new_y = model.predict(current_input)\n",
    "            y_pred.append(new_y[0][0])\n",
    "            # Remove the first value of the current input and append the new value to the end of the input sequence\n",
    "            current_input = np.append(current_input[:, :, 1:], new_y.reshape((1, 1, 1)), axis=2)\n",
    "        \n",
    "        y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "        print(\"Epochs: \", epoch)\n",
    "        print(\"Standardized MSE: \", mean_squared_error(val_y, y_pred))\n",
    "        print(\"Standardized MAE: \", np.mean(np.abs(val_y - y_pred)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Append the results to the epoch grid search results table\n",
    "        epoch_grid_search_results = pd.concat([epoch_grid_search_results, pd.DataFrame({'fold': [fold],'epoch': [epoch], 'MSE': [mean_squared_error(val_y, y_pred)], 'MAE': [np.mean(np.abs(val_y - y_pred))]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(epoch_grid_search_results)\n",
    "epoch_grid_search_results.to_csv('epoch_grid_search_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b416c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "epoch_grid_search_results = pd.read_csv('epoch_grid_search_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3195e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_average = epoch_grid_search_results.groupby('epoch').agg({'MSE': 'mean', 'MAE': 'mean'})\n",
    "# Write the average results to a CSV file\n",
    "epoch_average.to_csv('epoch_average.csv', index=False)\n",
    "epoch_average = pd.read_csv('epoch_average.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54941f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_EPOCH = int(epoch_grid_search_results.loc[epoch_grid_search_results['MSE'].idxmin()]['epoch'])\n",
    "print(\"Best epoch: \", BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lags in LAGS:\n",
    "    print(f\"Lag: {lags}\")\n",
    "    X, y = create_features(X_train_list, lags)\n",
    "\n",
    "    # Expanding window cross-validation\n",
    "    for fold, (train_set, validation_set) in enumerate(expanding_window_cv_sets(X, y, FOLDS)):\n",
    "        train_X, train_y = train_set\n",
    "        val_X, val_y = validation_set\n",
    "\n",
    "        # Reshape the data to be 3D for LSTM input\n",
    "        train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "        val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "        for hidden_units in HIDDEN_UNITS:\n",
    "            # Define the LSTM model with the current number of hidden units\n",
    "            model = Sequential([\n",
    "                LSTM(hidden_units, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False),\n",
    "                Dense(1)\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "            model.fit(train_X, train_y, epochs=BEST_EPOCH, batch_size=32, verbose=0)\n",
    "\n",
    "            # Recursively predict the validation set\n",
    "            current_input = val_X[0].reshape((1, 1, val_X.shape[2]))\n",
    "            y_pred = []\n",
    "\n",
    "            for i in range(len(val_y)):\n",
    "                new_y = model.predict(current_input)\n",
    "                y_pred.append(new_y[0][0])\n",
    "                current_input = np.append(current_input[:, :, 1:], new_y.reshape((1, 1, 1)), axis=2)\n",
    "\n",
    "            y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "            print(f\"Lag: {lags}, Hidden Units: {hidden_units}\")\n",
    "            print(\"Standardized MSE: \", mean_squared_error(val_y, y_pred))\n",
    "            print(\"Standardized MAE: \", np.mean(np.abs(val_y - y_pred)))\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # Append the results to the lag grid search results table\n",
    "            grid_search_results = pd.concat([grid_search_results, pd.DataFrame({'fold': [folds], 'lag': [lags], 'hidden_units': [hidden_units], 'MSE': [mean_squared_error(val_y, y_pred)], 'MAE': [np.mean(np.abs(val_y - y_pred))]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid_search_results)\n",
    "grid_search_results.to_csv('grid_search_results.csv', index=False)\n",
    "\n",
    "average_lag_units = grid_search_results.groupby(['lag', 'hidden_units']).agg({'MSE': 'mean', 'MAE': 'mean'})\n",
    "display(average_lag_units)\n",
    "# Write the average results to a CSV file\n",
    "average_lag_units.to_csv('average_lag_units.csv', index=False)\n",
    "average = pd.read_csv('average_lag_units.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac42ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.read_csv('grid_search_results.csv')\n",
    "average_lag_units = pd.read_csv('average_lag_units.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab2 = scipy.io.loadmat('Xtest.mat')\n",
    "X_matlab_test = matlab2['Xtest']\n",
    "X_test_list = X_matlab_test.flatten().tolist()\n",
    "\n",
    "concat_train_test = X_train_list + X_test_list\n",
    "fig = px.line(y=concat_train_test, x=range(len(concat_train_test)), title='Line Plot of X_train and X_test Values')\n",
    "fig.update_layout(xaxis_title='Index', yaxis_title='Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "number_of_lags = 35\n",
    "\n",
    "X, y = create_features(X_train_list, number_of_lags)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "\n",
    "# 16 units uit grid search \n",
    "model = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),\n",
    "    LSTM(50, activation='relu', dropout=0.2, return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Epochs uit initele grid search\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Now test the model on the test set, first create the features for the test set\n",
    "X_test, y_test = create_features(X_test_list, number_of_lags)\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "\n",
    "# Recursively predict the test set\n",
    "current_input = X_test[0].reshape((1, 1, X_test.shape[2]))\n",
    "y_test_pred = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    new_y = model.predict(current_input, verbose=0)\n",
    "    y_test_pred.append(new_y[0][0])\n",
    "    current_input = np.append(current_input[:, :, 1:], new_y.reshape((1, 1, 1)), axis=2)\n",
    "\n",
    "y_test_pred = np.array(y_test_pred).reshape(-1, 1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "\n",
    "# Plot the predictions vs actual values\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=y_test.flatten(), mode='lines', name='Actual Values'))\n",
    "fig.add_trace(go.Scatter(y=y_test_pred.flatten(), mode='lines', name='Predicted Values'))\n",
    "fig.update_layout(title='LSTM Predictions vs Actual Values', xaxis_title='Index', yaxis_title='Value')\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff343c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=y_test.flatten(), mode='lines', name='Actual Values'))\n",
    "fig.add_trace(go.Scatter(y=y_test_pred.flatten(), mode='lines', name='Predicted Values'))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Value',\n",
    "    legend=dict(\n",
    "        x=0.98,\n",
    "        y=0.98,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bgcolor='rgba(255, 255, 255, 0.7)',  # Optional: translucent white background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76971c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
