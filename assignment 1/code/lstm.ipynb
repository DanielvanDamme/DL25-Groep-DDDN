{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "matlab = scipy.io.loadmat('Xtrain.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = matlab['Xtrain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9037af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d881557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a list\n",
    "X_train_list = X_train.flatten().tolist()\n",
    "print(X_train_list)\n",
    "\n",
    "# Plot a line of the values in the training set\n",
    "fig = px.line(y=X_train_list, x=range(len(X_train_list)), title='Line Plot of X_train Values')\n",
    "fig.update_layout(xaxis_title='Index', yaxis_title='Value') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c473b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(timeseries_array, n_lags):\n",
    "    df = pd.DataFrame(timeseries_array, columns=['label'])\n",
    "    for i in range(1, n_lags + 1):\n",
    "        df[f'lag {i}'] = df['label'].shift(i)\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns=['label']).to_numpy()\n",
    "    y = df['label'].to_numpy()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_features(X_train_list, 10)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c94c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_cv_sets(X, y, folds: int, validation_split_ratio: float = 0.2):\n",
    "    \n",
    "    n = len(X)\n",
    "    fold_size = int(n / folds)\n",
    "\n",
    "    for fold in range(folds):\n",
    "        start_fold = fold * fold_size\n",
    "        end_fold = start_fold + fold_size\n",
    "\n",
    "        training_start = 0\n",
    "        training_end = int(end_fold - fold_size * validation_split_ratio)\n",
    "\n",
    "        validation_start = training_end\n",
    "\n",
    "        training_set = X[training_start:training_end], y[training_start:training_end]\n",
    "        validation_set = X[validation_start:end_fold], y[validation_start:end_fold]\n",
    "        yield training_set, validation_set\n",
    "\n",
    "# Example usage\n",
    "folds = 5\n",
    "for train_set, val_set in expanding_window_cv_sets(X, y, folds):\n",
    "    train_X, train_y = train_set\n",
    "    val_X, val_y = val_set\n",
    "\n",
    "    print(\"Training Set:\")\n",
    "    print(train_X.shape, train_y.shape)\n",
    "    print(\"Validation Set:\")\n",
    "    print(val_X.shape, val_y.shape)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ea6b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create two tables to store the results of CV grid search\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m epoch_grid_search_results = \u001b[43mpd\u001b[49m.DataFrame(columns=[\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m grid_search_results = pd.DataFrame(columns=[\u001b[33m'\u001b[39m\u001b[33mhidden_units\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlags\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create two tables to store the results of CV grid search\n",
    "epoch_grid_search_results = pd.DataFrame(columns=['epoch', 'fold', 'MSE', 'MAE'])\n",
    "grid_search_results = pd.DataFrame(columns=['hidden_units', 'lags', 'fold', 'MSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b94c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "EPOCHS = [20, 50, 100, 200, 500, 1000]\n",
    "LAGS = [5, 15, 25, 35, 50]\n",
    "HIDDEN_UNITS = [5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "folds = 5\n",
    "for epoch in EPOCHS:\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for train_set, val_set in expanding_window_cv_sets(X_scaled, y_scaled, folds):\n",
    "        train_X, train_y = train_set\n",
    "        val_X, val_y = val_set\n",
    "        \n",
    "        # Reshape the data to be 3D for LSTM input\n",
    "        train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "        val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "        # First, we are gonna fix the LSTM to 10 hidden units and grid search the epochs\n",
    "\n",
    "        # Define the lSTM model with 15 hidden units\n",
    "        model = Sequential([\n",
    "            LSTM(15, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(train_X, train_y, epochs=epoch, batch_size=32, verbose=0)\n",
    "\n",
    "        # Recursively predict the validation set, so start with the first example of the validation set and use the model to predict the next value, then use that value to predict the next one, and so on.\n",
    "        current_input = val_X[0].reshape((1, 1, val_X.shape[2]))\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(len(val_y)):\n",
    "            new_y = model.predict(current_input)\n",
    "            y_pred.append(new_y[0][0])\n",
    "            # Remove the first value of the current input and append the new value to the end of the input sequence\n",
    "            current_input = np.append(current_input[:, :, 1:], new_y.reshape((1, 1, 1)), axis=2)\n",
    "        \n",
    "        y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "        print(\"Epochs: \", epoch)\n",
    "        print(\"Standardized MSE: \", mean_squared_error(val_y, y_pred))\n",
    "        print(\"Standardized MAE: \", np.mean(np.abs(val_y - y_pred)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Append the results to the epoch grid search results table\n",
    "        epoch_grid_search_results = pd.concat([epoch_grid_search_results, pd.DataFrame({'epoch': [epoch], 'MSE': [mean_squared_error(val_y, y_pred)], 'MAE': [np.mean(np.abs(val_y - y_pred))]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(epoch_grid_search_results)\n",
    "epoch_grid_search_results.to_csv('epoch_grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54941f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_EPOCH = epoch_grid_search_results.loc[epoch_grid_search_results['MSE'].idxmin()]['epoch']\n",
    "print(\"Best epoch: \", BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lags in LAGS:\n",
    "    print(f\"Lag: {lags}\")\n",
    "    X, y = create_features(X_train_list, lags)\n",
    "\n",
    "    # Expanding window cross-validation\n",
    "    for train_set, validation_set in expanding_window_cv_sets(X, y, FOLDS):\n",
    "        train_X, train_y = train_set\n",
    "        val_X, val_y = validation_set\n",
    "\n",
    "        # Reshape the data to be 3D for LSTM input\n",
    "        train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "        val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "        for hidden_units in HIDDEN_UNITS:\n",
    "            # Define the LSTM model with the current number of hidden units\n",
    "            model = Sequential([\n",
    "                LSTM(hidden_units, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False),\n",
    "                Dense(1)\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "            model.fit(train_X, train_y, epochs=BEST_EPOCH, batch_size=32, verbose=0)\n",
    "\n",
    "            # Recursively predict the validation set\n",
    "            current_input = val_X[0].reshape((1, 1, val_X.shape[2]))\n",
    "            y_pred = []\n",
    "\n",
    "            for i in range(len(val_y)):\n",
    "                new_y = model.predict(current_input)\n",
    "                y_pred.append(new_y[0][0])\n",
    "                current_input = np.append(current_input[:, :, 1:], new_y.reshape((1, 1, 1)), axis=2)\n",
    "\n",
    "            y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "            print(f\"Lag: {lags}, Hidden Units: {hidden_units}\")\n",
    "            print(\"Standardized MSE: \", mean_squared_error(val_y, y_pred))\n",
    "            print(\"Standardized MAE: \", np.mean(np.abs(val_y - y_pred)))\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # Append the results to the lag grid search results table\n",
    "            grid_search_results = pd.concat([grid_search_results, pd.DataFrame({'lag': [lags], 'hidden_units': [hidden_units], 'MSE': [mean_squared_error(val_y, y_pred)], 'MAE': [np.mean(np.abs(val_y - y_pred))]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid_search_results)\n",
    "grid_search_results.to_csv('grid_search_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
