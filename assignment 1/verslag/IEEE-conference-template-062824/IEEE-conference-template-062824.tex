\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{TODO}

\author{\IEEEauthorblockN{DaniÃ«l Jochems}
\IEEEauthorblockA{\textit{TODO (student number)}}
\and
\IEEEauthorblockN{David}
\IEEEauthorblockA{TODO}
\and
\IEEEauthorblockN{Niek Grimbergen}
\IEEEauthorblockA{TODO}
\and
\IEEEauthorblockN{Daan van Dam}
\IEEEauthorblockA{6434657}
}

\maketitle

\begin{abstract}
TODO: Most important paragraph. Context (our question, the problem statement), content (here we go 
over what we did and what we found), conclusion (why/how it matters). Max 150 words.
\end{abstract}

\begin{IEEEkeywords}
TODO
\end{IEEEkeywords}

\section{Introduction}
TODO: Why does the paper matter? Set up gap in science/knowledge focusing down from a bigger 
problem to our smaller problem. Last paragraph should summarize our results to fill this gap. Here 
we can give context and background if we want than the abstract. We cannot give a conclusion, at 
most preview/tease the conclusion/results.

% Daan: I write this section with 'n' folds, if someone does some hyperparameter optimization with
% with the number of folds and finds empirically what is best then please replace the 'n' here with
% that number or put at the end we selected 'n = 5' or something.

% Daan: To predict 200 time points into the future for every model for prophet: 
% https://stackoverflow.com/questions/64822488/how-to-use-prophets-make-future-dataframe-with-multiple-regressors
% I recommend we do not do this, so let's just do it for LTSM or the best model.

\section{Methods}
\subsection{Training data procedures}
First we normalize the data to zero mean and unit variance. We then split the normalized time 
series data in $n$-folds. These folds are further divided in train and validation folds with a 
ratio of $80/20$ respectively. We then train on the train fold(s) and validate on the validation 
folds. Every fold the train fold grows by concatenating the previous and current folds train fold, 
aka an accumulating train fold. The validation fold remains the same size.

% Daan: I used mean absolute error as a metric
Every iteration we validate on the validation fold and save the metrics and an increasing weight. 
The metrics over the folds are averaged taking into account these weights using the following
formula:

$$avg = \frac{\sum_{i=1}^{n}(\text{MEA}_{fold_n} * weight_n)}{\sum_{i=1}^n weight_n}$$

% Train and test loss over epochs figuren.
\subsection{Prophet (Meta)}
TODO: beschrijf hoe Prophet werkt, wat betreft hoe de data aangeleverd wordt met de lags en de 
vergelijking die ik maakte met lineaire regressie aanpak en waarom het slecht was.

\section{Results}
TODO: This should be a sequence of statements each supported with some evidence and a conclusion.
Each statement is a subsection, the first paragraph of a statement summarizes the overall approach 
to solving the problem stated in the introduction, explain essential features of existing methods
we use and necessary background information. If we made a method ourselvers point it out clearly. 
Figures must be self contained (the legend and caption should have all the info for the figure).

\section{Discussion}
TODO: First we discuss how the gap from the introduction was filled by the report, the limitations
of the approach, some future directions and perhaps an open problem we find. Afterwards Basically 
everything we put some time into but did not write out to a result can be put here and anything we 
wanted to do but did not can also be put here.

\section*{AI statement}
TODO: If we used machine learning generative AI to do anything we put it here.

\section*{References}

\end{document}
